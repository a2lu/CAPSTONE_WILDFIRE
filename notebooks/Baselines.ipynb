{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040f785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import Polygon, LineString, MultiPolygon\n",
    "from shapely.ops import split\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6417008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burned = gpd.read_file(\"../data/burned/sampleData.csv\")\n",
    "# unburned = gpd.read_file(\"../data/unburned/sampleData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f186607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors = pd.concat([burned,unburned])\n",
    "# neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "258538f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame()\n",
    "for i in ['CASCADE.csv', 'BALD.csv', 'REDWOOD VALLEY.csv', 'COVE.csv', 'CALDWELL.csv', 'BUTTE.csv', 'BUCK.csv', 'WALKER.csv', 'HAPPY.csv', 'CARR.csv', 'ROCKY.csv', 'OAK.csv', 'KING.csv', 'KINCADE.csv', 'ATLAS.csv', 'CAMP.csv','FRYING PAN.csv']:\n",
    "    temp = pd.read_csv('../data/rasterCSV/'+str(i))\n",
    "    names=[i[:len(i)-4]]*temp.shape[0]\n",
    "    temp['name'] = names\n",
    "    clean_df = pd.concat([temp,clean_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7277939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('../data/rasterCSV/'+'FRYING PAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c5d5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp1 = gpd.GeoDataFrame()\n",
    "# temp2 = gpd.GeoDataFrame()\n",
    "# for i in np.unique(burned['FIRE_NAME']):\n",
    "#     temp1 = pd.concat([temp1,burned[burned['FIRE_NAME']==i]])\n",
    "#     temp2 = pd.concat([temp2,unburned[unburned['FIRE_NAME']==i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70613bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lands = OneHotEncoder().fit_transform(np.array(clean_df['landCover']).reshape(-1,1))\n",
    "lands = pd.DataFrame.sparse.from_spmatrix(lands, columns= range(6))\n",
    "clean_df = clean_df.reset_index().drop(columns='index')\n",
    "X_train_t = pd.concat([lands, clean_df], axis=1)\n",
    "clean_df = X_train_t\n",
    "clean_df = clean_df[[0,\n",
    " 1,\n",
    " 2,\n",
    " 3,\n",
    " 4,\n",
    " 5,\n",
    " 'SR_B1',\n",
    " 'SR_B2',\n",
    " 'SR_B3',\n",
    " 'SR_B4',\n",
    " 'SR_B5',\n",
    " 'SR_B6',\n",
    " 'SR_B7',\n",
    " 'NDVI',\n",
    " 'elevation',\n",
    " 'percent_tree_cover',\n",
    "'burnSeverity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dec9631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-62340587ab3f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df[i]=pd.to_numeric(clean_df[i], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>SR_B1</th>\n",
       "      <th>SR_B2</th>\n",
       "      <th>SR_B3</th>\n",
       "      <th>SR_B4</th>\n",
       "      <th>SR_B5</th>\n",
       "      <th>SR_B6</th>\n",
       "      <th>SR_B7</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>elevation</th>\n",
       "      <th>percent_tree_cover</th>\n",
       "      <th>burnSeverity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7835</td>\n",
       "      <td>7945</td>\n",
       "      <td>8753</td>\n",
       "      <td>8107</td>\n",
       "      <td>21454</td>\n",
       "      <td>11501</td>\n",
       "      <td>8826</td>\n",
       "      <td>451</td>\n",
       "      <td>558</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7794</td>\n",
       "      <td>7904</td>\n",
       "      <td>8654</td>\n",
       "      <td>8034</td>\n",
       "      <td>21443</td>\n",
       "      <td>11210</td>\n",
       "      <td>8669</td>\n",
       "      <td>454</td>\n",
       "      <td>544</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7792</td>\n",
       "      <td>7878</td>\n",
       "      <td>8596</td>\n",
       "      <td>8002</td>\n",
       "      <td>20576</td>\n",
       "      <td>11125</td>\n",
       "      <td>8683</td>\n",
       "      <td>439</td>\n",
       "      <td>521</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7637</td>\n",
       "      <td>7709</td>\n",
       "      <td>8155</td>\n",
       "      <td>7736</td>\n",
       "      <td>16503</td>\n",
       "      <td>9872</td>\n",
       "      <td>8196</td>\n",
       "      <td>361</td>\n",
       "      <td>513</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7608</td>\n",
       "      <td>7659</td>\n",
       "      <td>8065</td>\n",
       "      <td>7658</td>\n",
       "      <td>15235</td>\n",
       "      <td>9619</td>\n",
       "      <td>8132</td>\n",
       "      <td>330</td>\n",
       "      <td>506</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380661</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8156</td>\n",
       "      <td>8341</td>\n",
       "      <td>8965</td>\n",
       "      <td>9020</td>\n",
       "      <td>15535</td>\n",
       "      <td>12553</td>\n",
       "      <td>10065</td>\n",
       "      <td>265</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380662</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8229</td>\n",
       "      <td>8393</td>\n",
       "      <td>9007</td>\n",
       "      <td>9188</td>\n",
       "      <td>15785</td>\n",
       "      <td>13556</td>\n",
       "      <td>10771</td>\n",
       "      <td>264</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380663</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8602</td>\n",
       "      <td>8890</td>\n",
       "      <td>9542</td>\n",
       "      <td>10364</td>\n",
       "      <td>15031</td>\n",
       "      <td>15533</td>\n",
       "      <td>12149</td>\n",
       "      <td>183</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380664</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8602</td>\n",
       "      <td>8890</td>\n",
       "      <td>9542</td>\n",
       "      <td>10364</td>\n",
       "      <td>15031</td>\n",
       "      <td>15533</td>\n",
       "      <td>12149</td>\n",
       "      <td>183</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8296</td>\n",
       "      <td>8520</td>\n",
       "      <td>9175</td>\n",
       "      <td>9664</td>\n",
       "      <td>14499</td>\n",
       "      <td>13575</td>\n",
       "      <td>10948</td>\n",
       "      <td>200</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4380666 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1    2    3    4    5  SR_B1  SR_B2  SR_B3  SR_B4  SR_B5  \\\n",
       "0        0.0  0.0  1.0  0.0  0.0  0.0   7835   7945   8753   8107  21454   \n",
       "1        0.0  0.0  1.0  0.0  0.0  0.0   7794   7904   8654   8034  21443   \n",
       "2        0.0  0.0  1.0  0.0  0.0  0.0   7792   7878   8596   8002  20576   \n",
       "3        0.0  0.0  1.0  0.0  0.0  0.0   7637   7709   8155   7736  16503   \n",
       "4        0.0  0.0  1.0  0.0  0.0  0.0   7608   7659   8065   7658  15235   \n",
       "...      ...  ...  ...  ...  ...  ...    ...    ...    ...    ...    ...   \n",
       "4380661  0.0  0.0  0.0  1.0  0.0  0.0   8156   8341   8965   9020  15535   \n",
       "4380662  0.0  0.0  0.0  1.0  0.0  0.0   8229   8393   9007   9188  15785   \n",
       "4380663  0.0  0.0  0.0  1.0  0.0  0.0   8602   8890   9542  10364  15031   \n",
       "4380664  0.0  0.0  0.0  1.0  0.0  0.0   8602   8890   9542  10364  15031   \n",
       "4380665  0.0  0.0  0.0  1.0  0.0  0.0   8296   8520   9175   9664  14499   \n",
       "\n",
       "         SR_B6  SR_B7  NDVI  elevation  percent_tree_cover  burnSeverity  \n",
       "0        11501   8826   451        558                  74             2  \n",
       "1        11210   8669   454        544                  76             2  \n",
       "2        11125   8683   439        521                  79             2  \n",
       "3         9872   8196   361        513                  81             2  \n",
       "4         9619   8132   330        506                  82             2  \n",
       "...        ...    ...   ...        ...                 ...           ...  \n",
       "4380661  12553  10065   265        338                   0             2  \n",
       "4380662  13556  10771   264        332                   0             2  \n",
       "4380663  15533  12149   183        327                   0             2  \n",
       "4380664  15533  12149   183        318                   0             2  \n",
       "4380665  13575  10948   200        309                   0             2  \n",
       "\n",
       "[4380666 rows x 17 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in clean_df.columns:\n",
    "    clean_df[i]=pd.to_numeric(clean_df[i], errors='coerce')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dad01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test[['SR_B1',\n",
    "#  'SR_B2',\n",
    "#  'SR_B3',\n",
    "#  'SR_B4',\n",
    "#  'SR_B5',\n",
    "#  'SR_B6',\n",
    "#  'SR_B7',\n",
    "#  'NDVI',\n",
    "#  'elevation',\n",
    "#  'percent_tree_cover',\n",
    "#  'landCover','burnSeverity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d947a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors= neighbors[['SR_B1',\n",
    "#  'SR_B2',\n",
    "#  'SR_B3',\n",
    "#  'SR_B4',\n",
    "#  'SR_B5',\n",
    "#  'SR_B6',\n",
    "#  'SR_B7',\n",
    "#  'NDVI',\n",
    "#  'elevation',\n",
    "#  'percent_tree_cover',\n",
    "#  'landCover','burnSeverity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "037b200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicelu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4463: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "/Users/alicelu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.10924143, -0.20573535,  1.10297291, ...,  3.06821893,\n",
       "        -0.70302849,  1.23064532],\n",
       "       [-0.10924143, -0.20573535,  1.10297291, ...,  3.10097786,\n",
       "        -0.72868873,  1.29712175],\n",
       "       [-0.10924143, -0.20573535,  1.10297291, ...,  2.93718322,\n",
       "        -0.77084485,  1.39683639],\n",
       "       ...,\n",
       "       [-0.10924143, -0.20573535, -0.90664058, ...,  0.14175472,\n",
       "        -1.12642256, -1.22898254],\n",
       "       [-0.10924143, -0.20573535, -0.90664058, ...,  0.14175472,\n",
       "        -1.14291843, -1.22898254],\n",
       "       [-0.10924143, -0.20573535, -0.90664058, ...,  0.32738865,\n",
       "        -1.1594143 , -1.22898254]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean_df = neighbors[['SR_B1',\n",
    "#  'SR_B2',\n",
    "#  'SR_B3',\n",
    "#  'SR_B4',\n",
    "#  'SR_B5',\n",
    "#  'SR_B6',\n",
    "#  'SR_B7',\n",
    "#  'NDVI',\n",
    "#  'elevation',\n",
    "#  'percent_tree_cover',\n",
    "#  'landCover','burnSeverity']]\n",
    "for i in clean_df.columns:\n",
    "    clean_df[i].fillna(value=clean_df[i].mean(), inplace=True)\n",
    "X_train = copy.deepcopy(clean_df.drop(['burnSeverity'],axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.values)\n",
    "Xt_scaled = scaler.transform(X_train)\n",
    "Xt_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85de83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = neighbors['burnSeverity'].values\n",
    "# clean_df = test\n",
    "# for i in clean_df.columns:\n",
    "#     clean_df[i].fillna(value=clean_df[i].mean(), inplace=True)\n",
    "# X_train = copy.deepcopy(clean_df.drop(['burnSeverity'],axis=1))\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train.values)\n",
    "# Xtest_scaled = scaler.transform(X_train)\n",
    "# y_test = test['burnSeverity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0b5ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicelu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.7941250995852233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicelu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values)\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xt_scaled, encoded,test_size=0.2)\n",
    "pipe = LogisticRegression(max_iter=600)\n",
    "pipe.fit(x_train, y_train.ravel())\n",
    "print(\"Logistic Regression: \"+str(pipe.score(x_test, y_test)))\n",
    "importance = pipe.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "548f711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = {0:'Other',1:'Developed',2:'Forest',3:'Shrub',4:'Grassland',5:'Agriculture'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "625a4884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other: 0.05392497731838588\n",
      "Developed: -0.14529018845024105\n",
      "Forest: 0.20939933603161387\n",
      "Shrub: -0.09672240475206412\n",
      "Grassland: 0.07963187725826743\n",
      "Agriculture: -0.4034186479720794\n",
      "SR_B1: -0.4261466675340333\n",
      "SR_B2: -0.43170828964399616\n",
      "SR_B3: 6.119652611162454\n",
      "SR_B4: 0.9692337387367699\n",
      "SR_B5: -3.4956864263838963\n",
      "SR_B6: 0.28996660589011597\n",
      "SR_B7: -4.350705921005426\n",
      "NDVI: 5.414847979623502\n",
      "elevation: 0.5015807566288937\n",
      "percent_tree_cover: -3.238424113647026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 'SR_B1',\n",
       " 'SR_B2',\n",
       " 'SR_B3',\n",
       " 'SR_B4',\n",
       " 'SR_B5',\n",
       " 'SR_B6',\n",
       " 'SR_B7',\n",
       " 'NDVI',\n",
       " 'elevation',\n",
       " 'percent_tree_cover']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    if str(X_train.columns[i])=='0' or str(X_train.columns[i])=='1' or str(X_train.columns[i])=='2' or str(X_train.columns[i])=='3' or str(X_train.columns[i])=='4' or str(X_train.columns[i])=='5':\n",
    "        print(landcover[X_train.columns[i]]+\": \"+str(importance[i]))\n",
    "    else:\n",
    "        print(str(X_train.columns[i])+\": \"+str(importance[i]))\n",
    "    if importance[i] >= 0.02 or importance[i]<=-0.02:\n",
    "        keep.append(X_train.columns[i])\n",
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64debd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'logistic_regression.sav'\n",
    "# pickle.dump(pipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7487a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values.ravel())\n",
    "x_train = Xt_scaled\n",
    "mlp100 = MLPClassifier(max_iter=100).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6379e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'mlp.sav'\n",
    "# pickle.dump(mlp100, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66665cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "# lab_enc = preprocessing.LabelEncoder()\n",
    "# encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values)\n",
    "# x_train, x_test = Xt_scaled, Xtest_scaled, \n",
    "# etc50 = ExtraTreesClassifier(n_estimators=50)\n",
    "# etc50.fit(x_train, y_train)\n",
    "# print(\"Extra Trees Classifier: \"+str(etc50.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6746f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicelu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "#https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values)\n",
    "x_train= Xt_scaled\n",
    "clf = ExtraTreesClassifier(n_estimators=10)\n",
    "clf.fit(x_train, y_train)\n",
    "# print(\"Extra Trees Classifier: \"+str(clf.score(x_test, y_test)))\n",
    "# importance = clf.feature_importances_\n",
    "# keep = []\n",
    "# for i in range(len(X_train.columns)):\n",
    "#     print(X_train.columns[i]+\": \"+str(importance[i]))\n",
    "#     if importance[i] >= 0.02:\n",
    "#         keep.append(X_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23979368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'etc.sav'\n",
    "# pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'extra_trees_pickle.sav'\n",
    "# pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "# Calculation of Mean Squared Error (MSE)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c60c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values)\n",
    "x_train, x_test = Xt_scaled, Xtest_scaled\n",
    "xbg = XGBClassifier()\n",
    "xbg.fit(x_train, y_train)\n",
    "xbg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a63cdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicelu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values)\n",
    "x_train= Xt_scaled\n",
    "rfc100 = RandomForestClassifier(n_estimators=100)\n",
    "rfc100.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd54475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicelu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 1.5 s, total: 2min 7s\n",
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values)\n",
    "x_train= Xt_scaled\n",
    "rfc100 = RandomForestClassifier(n_estimators=10)\n",
    "rfc100.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec1a28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'rfc.sav'\n",
    "# pickle.dump(rfc100, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdbe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = clf.feature_importances_\n",
    "keep = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    print(X_train.columns[i]+\": \"+str(importance[i]))\n",
    "    if importance[i] >= 0.02:\n",
    "        keep.append(X_train.columns[i])\n",
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIRE_NAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[df['FIRE_NAME']=='CARR']\n",
    "clean_df = temp[['burnSeverity','SR_B3','SR_B6','NDVI','elevation','percent_tree_cover','x_coord','y_coord']]\n",
    "for i in clean_df.columns:\n",
    "    clean_df[i]=pd.to_numeric(clean_df[i], errors='coerce')\n",
    "for i in clean_df.columns:\n",
    "    clean_df[i].fillna(value=clean_df[i].mean(), inplace=True)\n",
    "X_train = clean_df.drop(['burnSeverity'],axis=1)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.values)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(clean_df[['burnSeverity']].values)\n",
    "x_train = clean_df[['SR_B3','SR_B6','NDVI','elevation','percent_tree_cover','x_coord','y_coord']]\n",
    "y_train = clean_df[['burnSeverity']]\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "temp = df[df['FIRE_NAME']=='FRYING PAN']\n",
    "clean_df = temp[['burnSeverity','SR_B3','SR_B6','NDVI','elevation','percent_tree_cover','x_coord','y_coord']]\n",
    "for i in clean_df.columns:\n",
    "    clean_df[i]=pd.to_numeric(clean_df[i], errors='coerce')\n",
    "for i in clean_df.columns:\n",
    "    clean_df[i].fillna(value=clean_df[i].mean(), inplace=True)\n",
    "x_test = clean_df[['SR_B3','SR_B6','NDVI','elevation','percent_tree_cover','x_coord','y_coord']]\n",
    "y_test = clean_df[['burnSeverity']]\n",
    "y_pred = clf.predict(x_test)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c86b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_pred - y_test['burnSeverity'])**2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
